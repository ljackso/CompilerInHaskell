
\chapter{Parsing}

Parsing is a fundamental part of compiling, you can think of it as the front end of the compiler. In simplistic terms it takes in a program as raw text and then builds a data structure that represents the program the user has written. In my project the raw text is the code from a .gol file and the data structure is the intermediate representation of Goal. 

Although I will be talking a lot about the intermediate representation I've created to parse my text into, I will not be going into much detail about the design of that data structure. That is covered in more detail in the next chapter. In this section a preexisting understanding of Monads in Haskell is assumed.      

\section[Introduction to Using Monadic Parser Combinators]{Introduction to Using \\ Monadic Parser Combinators}

The technique I used to parse data in my compiler was to make use of Monadic Parser Combinators. If we think of a parser in Haskell as something that takes in a string and returns a data structure, we can think of parser combinators as high order functions that take in several parsers as its input and returns a new parser as it's output. 

A lot of the comments in the section makes use of two papers on monadic parser combinators both \cite{Hutton96} and \cite{Hutton98} also making use of a library of parsers provided in the later. 

We can first look at the type of the parsers provided;

\begin{lstlisting}
	newtype Parser a = Parser (String -> [(a,String)])
\end{lstlisting}  

You can see that our parser takes in a string returning a list of results. We can see that our parser will have the type $Parser$ $Prog$ as we need our parser to output the type $Prog$ which is the type of my intermediate representation and the type which my code generator takes in. 

The best way to understand how parser combinators work is too look at a few examples that you will find in Parsing.lhs provide by \cite{Hutton98}.

If we first look at the $item$ parser. Which just consumes the first character of a string, and fails if the string is null. 

\newpage

\begin{lstlisting}
item   :: Parser Char
item   =  P (\inp -> case inp of
                       []     -> []
                       (x:xs) -> [(x,xs)])
\end{lstlisting}

We can see that on it's own this parser isn't particularly useful, but with the use of parser combinators we can put it to some use. Now say we want to make use of this parser to parse digits. We need to first look at how we allow for conditional parsing, compared to $item$ which will parse anything as long as it is not an empty string. 

If we look at $sat$ we can see how it makes use of $item$ to allow for parsing on some condition;

\begin{lstlisting}
sat    :: (Char -> Bool) -> Parser Char
sat p  =  do x <- item
             if p x then return x else failure
\end{lstlisting}

You may also notice the use of $failure$ which has type  $Parser$ $a$ and is a parser that will always fail regardless of input. 

We can now make use of $sat$ to create a parser to parse digits;

\begin{lstlisting}
	digit  :: Parser Char
	digit  =  sat isDigit
\end{lstlisting}

This highlights how parser combinators work, by combing several parsers we are able to begin to create something useful. Using the same technique we could easily create parsers for specific characters or to only parser upper or lower case characters.

This is an incredibly brief introduction into a very interesting topic and it is recommend that the interested reader refer to either of papers referenced earlier to learn more about creating monadic parser combinators.

\section{Goal Syntax Rules and Justifications}

As was discussed in the previous structure Goal gets most of its syntax rules from Go. There are however some unique syntax rules I decided to implement in Goal that you will not find in Go. There were two main reasons why syntax rules my differ from Go. 

The first being it was a design choice. For example if you look at variable declaration in Go it can be done one of 2 ways.

\begin{lstlisting}
	var i int = 42
	j := 42
\end{lstlisting}    

Although I could have implemented variable declarations to look like this I decided because variables can be declared on the fly and because of the simplistic nature of my type system I may as well keep declarations and assignments the same, and as simple as possible. Hence in Goal all you need to write to declare or assign a variable is;

\begin{lstlisting}
	l = 42;
\end{lstlisting}
 
There are several examples of these changes in syntax for design choice, such as global variable definitions and the requirement of brackets to hold conditional statements. These small changes where made merely as a way to tidy up Goal and make it have a more complete and consistent syntax. 

The other reason Goal's syntax varies from Go is because of the limitations within the implementation of my parser. 

For example, in Go you don't need to use semi colons at the end of a command. Where as I decided that in Goal I would make it necessary to include semi colons at the end of every command, including if statements and function declarations. For example;

\begin{lstlisting}
	func main() {
	    i = 2;
	    j = 0;
	    for (i < 100){
	        i = square(i);
	        j ++;
	    };
	    Show(j);		
	};
	
	func square(n int) int {
		return n * n;
	};
\end{lstlisting}

You can see in this simple program how every command even function definitions and for loops need to finish with a semi colon.

This is because it makes it easier to split up commands based on every time I see a semi colon. The reasons I made some of these choices was not because it was not possible for me to implement different syntax rules, but because the main focus of this project was not on parsing and if a small change to syntax meant a quicker implementation sometimes I felt it necessary. 


\section{Parser Implementation}

My parser implementation was focused around using monadic parser combinators. As part of this I used a collection of functions provided from the \cite{Hutton98}.These can be seen in my abstract in the Parsing.lhs file. What these functions do is provide a series of simple parsers to use when creating more complicated parser combinators. 

Then it was simply a question of building up parsers to handle more restrictive rules. A good way to understand this is to walk through a simple example of parsing comparative expressions. 

Although this section gives a walk through of how I used parser combinators, it should not be considered a standalone introduction. 

\newpage

\subsection{Example of Parser Implementation}

If we first start with defining the data structure, also known as the intermediate representation we wish to parse down to, we can then look to define the language which we are parsing;

%TODO check all code works
\begin{lstlisting}
data Expr 	= CompExpr Op Expr Expr | Val Number
	
data Op		= EQU | NEQ 
	
type Number	= Int 
\end{lstlisting}

This is a pretty simple data structure representing two types of conditional expressions. We now need to define a grammar that is acceptable for our language. A grammar, or formal grammar, is a set of rules by which valid sentences (or in our case commands and expressions) in a language are constructed \footnotemark[1].  In this case when we talk about a language we are not talking about a programming language in the typical sense, instead we define a language as a set of strings made of symbols that our limited by rules that are specific to that language \footnotemark[2]. 

\footnotetext[1]{\url{http://dragonbook.stanford.edu/lecture-notes/Stanford-CS143/06-Formal-Grammars.pdf}}
\footnotetext[2]{\url{http://en.wikipedia.org/wiki/Formal_language}}

To define our grammar it is good to look at some examples of what is acceptable in our little language, if we say we are only interested at looking at conditionals where you use $==$ to signify equals and $!=$ to signify two values being not equal;

\begin{lstlisting}
	4 == 7
	5 != 5
	42 == 42
	12 != 34 
\end{lstlisting}

You may notice that the expressions we are allowing don't have to be true. In this example we are allowing the user to express comparative expressions our parser has no need to deal with what is and isn't allowed computationally as long as our grammar allows it, the expression can be as bizarre as you want. This shows how we have to be careful defining our grammar to only allow what we want. For example if we look at our data structures we actually allow for some nested comparisons.

\newpage

You can see that in our data structure the following expression is valid;

\begin{lstlisting}
CompOp EQU 
	(CompOp NEQ 
		(Val 5) 
		(CompOP EQU 
			(Val 4)
			(Val 7))) 
	(CompOp NEQ 
		(Val 3) 
		(Val 5))
\end{lstlisting}

Which would look like this;

\begin{lstlisting}
 (5 != (4 == 7)) == (3 == 5)
\end{lstlisting}

Now you can argue this makes sense and should be allowed but I feel like in our simple language it's not what we want to include, also we need to consider if we end up including more types of comparisons, such as $>$ or $\geq$. Things will start to get messy quickly. Regardless of the justification for this example we won't allow nested comparisons. 

There are two ways to handle this problem. We can either alter our data structure so that it is no longer allowed, or we can create a grammar that does not allow for nested comparisons in our language. It is better to restrict our grammar than our intermediate representation. So we now need to define our grammar. In simple terms we can describe it as;

\begin{lstlisting}
 <NUMBER1> <COPARISON OPERATION> <NUMBER2>
\end{lstlisting}   	

Though we need to create a more formal definition. Lets say a sentence in our language has to consist of one natural number followed by either a $==$ or $!=$ then another natural number. We will allow white space between the numbers and comparison operators.By natural numbers we are referring to any whole number. 

To create a parser to handle this grammar we will need to make use of some parsers provided in Parsing.lhs;

\begin{itemize}
\item $natural$, will parse natural numbers
\item $symbol s$ will parse the given symbol s 
\end{itemize}

Making use of this we can use of Haskell's do notation we can also generate a parser to parse the different conditional symbols $==$ and $!=$. 

\begin{lstlisting}
	parseOp   :: Parser Op
	parseOp   = do symbol "=="
	               return (EQU)
        	     +++ do symbol "!="
	                    return (NEQ) 
\end{lstlisting} 

\newpage

Using parse combinators means we can combine multiple parsers. Using this approach we can now create code to evaluate conditional expressions allowed in our language;

%TODO check all this code
\begin{lstlisting}

evalCompExpr    :: String -> Expr
evalCompExpr xs = case (parse compExpr xs) of
                    [(e,[])]  -> e
                    [(_,o)]   -> error ("unused "++ o)
                    []        -> error "invalid"

parseComp        :: Parser Expr	
parseComp        = do n1 <- natural
                      o  <- parseOp 
                      n2 <- natural
                      return (CompOp o n1 n2)  
\end{lstlisting}

This example shows how you build a simple parser using monadic parser combinators and the Haskell script provided %TODO cite grahams paper %
. It shows the the process of building up a grammar to define your language and also begins to show the process of combing parsers. 


\subsection{Analysis and Expansion of Parser Example}

Looking at this example you can see the process of slowly building up a grammar and the parsers to enforce it.

There are a number of important ideas shown in this example, one of the most important concepts is the idea of making sure your parser is more restrictive than your data structure. There are several aspects of my intermediate representation that allow for features that are restricted in my grammar. The reason this is done is because it makes generating code simpler without really making my parser any more complex.  

Another good thing too take away from this is the idea of abstracting problems out, because our final parser could have easily have looked like this;

\begin{lstlisting}
parseComp        :: Parser Expr	
parseComp        = do n1 <- natural
                      do symbol "==" 
                         n2 <- natural
                         return (CompOp EQU n1 n2)
                       +++ do symbol "!="
                              n3 <- natural
                              return (CompOp NEQ n1 n3)
\end{lstlisting}

But because of the creation of our $parseOp$ function not only were we able to have a much cleaner implementation, we also made it  much easier to expand our parser to include more comparison operations.

One concept that is not touched upon in this example is the idea of having a hierarchy of bindings. If we take the idea of operator precedences within mathematical expressions. If we want a multiplication to be done before an addition in our language we need to generate an intermediate representation that will show this.

By combining multiple parsers we can create a hierarchy were an addition expression is dealt with before anything else by splitting on the $+$ symbol first. Then nesting other arithmetic expressions within the output of the first parser. Examples of this technique can be seen throughout the implementation of my parser.


\section{Potential for Expansion}

Parsing is a topic that could easily become the main focus of a project like this. The idea behind using parser combinators was that they had been something I was interested in exploring and the more I used them the more I began to see how they could take up more of this project. Instead I decided to focus this project in other areas but that does leave a list of areas I would be interested in coming back too. 

One of the main things you could expand within my parser would be to add some lexical analysis before beginning parsing. lexical analysis is used to identify a valid set of words used in the language \cite[p.~13]{CompDes2005}. It is useful as it means you do not begin actually parsing before being certain that only valid commands exist in each program.

Another big area for expansion would have been spending more time looking into being able to add more types. You will notice looking at my code that my compiler and executor can handle doubles. But unfortunately due to limitations with my parsing I decided against including it in the final release of Goal because I wanted to focus more time elsewhere.   
 